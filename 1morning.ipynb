{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIING OPINION FEATURES IN CUSTOMER REVIEWS\n",
    "### by Minqing Hu and Bing Liu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract of research paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MOTIVE\n",
    "\n",
    "In order to enhance customer satisfaction and their shopping experiences, online merchants enable their customers to review or to express opinions on the\n",
    "products that they buy.\n",
    "\n",
    "With expansion of e-commerce, online shopping, more and more common users reviewing products, the comments becomes incomprehensible, and looses its meaning. This makes it very hard for a potential customer to read them to help him or her to make a decision on whether to buy the product.\n",
    "\n",
    "In this research, we propose to study the problem of feature-based opinion summarization of customer reviews of  products sold online. The task is performed in two steps:\n",
    "1. Identify the features of the product that customers have expressed opinions on (called opinion features), rank the features according to their frequencies that they appear in the reviews.\n",
    "2. For each feature, we identify how many customer reviews have positive or negative opinions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OBJECTIVE\n",
    "This project aims to summarize all the customer reviews of a product.\n",
    "Unlike traditional summarization tasks, author aims to provide a specific feature of a product that a customer have opinion on, and also if the opinion is positive or negative.\n",
    "###### In this paper, author is only focusing on mining opinions/ product features that the reviewers have commented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### APPROACH\n",
    "The paper proposes a number of techniques based on data mining and NLP methods to mine opinions/ product features.\n",
    "The system, after crawling through all reviews, creates a \"REVIEW DATABASE\".\n",
    "The paper incorporates 2 techniques for discovering terms:\n",
    "1. Symbolic Approach : relies on SYNTACTIC DESCRIPTION of terms, namely noun phrase.\n",
    "2. Statistical Approach : to find the infrequent features by exploiting the fact that people uses same adjectives to describe different subjects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODEL\n",
    "<img src = \"model.jpg\">\n",
    "\n",
    "##### 1. POS Tagging\n",
    "Since the tasks focus on finding features that appear explicitly as nouns or noun phrases in the reviews. To them from the reviews, part-of-speech tagging is used.\n",
    "Each sentence is saved in Review database along with a pos tag with each word.\n",
    "A Transaction file is then created after preprocessing , which includes deletion of stopwords, stemming and fuzzy matching.\n",
    "##### 2.  Frequent feature generation\n",
    "This step is to find features that people are most interested in. In order to do this, Association rule mining to find all frequent itemsets is used. Considering \"itemset\" as a set of words or a phrase that occurs together.\n",
    "##### 3. Feature Pruning\n",
    "Since not all frequent features generated by Association rule mining are useful or geniune features, therefore feature pruning is necessary. There are 2 techniques used in the paper :-\n",
    "1. Compactness prunning : for a feature phrase and a sentence that contans the phrase, looking at POSITION INFORMATION of every word of phrase and check whether it is \"COMPACT\" (see def. in paper) or not in the sentence. If there are not even 2 sentences in review database, the feature phrase is pruned.\n",
    "2. Redundance pruning : If a feature has a \"p-Support\" lower than specified minimum value (3  in paper), and, feature is subset of another feature phrase, then it is pruned.\n",
    "\n",
    "##### 4. Opinion word extraction\n",
    "Opinion words are words that people use to express a positive or negative opinion.\n",
    "Observing that people often express their opinions of a product feature using opinion words that are located around the feature in the sentence, we can extract opinion words from the review database using all the remaining frequent features (after pruning). Saving after stemming and fuzzy-matching to create \"Opinion word list\".\n",
    "##### 5. Infrequent feature identification\n",
    "The observation “opinions tend to appear closely together with features” can be used to identify infrequent features.\n",
    "For each sentence in the review database, if it contains no frequent feature but one or more opinion words, the nearest noun/noun phrase of the opinion word is then stored in the feature set as an infrequent feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = 'data/'\n",
    "def getList():\n",
    "    global data_dir\n",
    "    prod_list = os.listdir(data_dir)\n",
    "    for p in prod_list:\n",
    "        print (p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_RDB (prod_name):\n",
    "    f = data_dir + prod_name + \".txt\"\n",
    "    with open(f, 'r') as content_file:\n",
    "        content = content_file.read()\n",
    "    content = ( content.split(\"##\") )\n",
    "    line = ''\n",
    "    for l in content:\n",
    "        line += l\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tagIt (data):\n",
    "\ttry :\n",
    "\t\tfor item in data:\n",
    "\t\t\tprint (item)\n",
    "\t\t\tbreak\n",
    "\texcept Exception:\n",
    "\t\tprint (\"Sorry.. exception occurred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tag (data):\n",
    "    try :\n",
    "        for item in data:\n",
    "            tokenized = nltk.word_tokenize (item)\n",
    "            tagged = nltk.pos_tag (tokenized)\n",
    "            print (tagged)\n",
    "\n",
    "    except Exception:\n",
    "        print (\"Sorry.. exception occurred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "def normalize (content):\n",
    "#     tok_list = [(ps.stem(w)).lower() for w in content]\n",
    "#     tok_list = [w for w in tok_list if not w in  ['(',')','%','``','.',',', '\\'',\"''\",\"'s\"]]\n",
    "#     filtered_sentence = [w for w in tok_list if len(w)>1]\n",
    "#     print (filtered_sentence)\n",
    "    tok_list = [w.lower() for w in content]\n",
    "    tok_list = [w for w in tok_list if not w in  ['(',')','%','``','.',',', '\\'',\"''\",\"'s\",\"#\"]]\n",
    "    print (tok_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Don't get\n"
     ]
    }
   ],
   "source": [
    "rdb = get_RDB (\"ipod\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
